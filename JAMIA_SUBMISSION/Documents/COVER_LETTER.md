Syaiful Bachri Mustamin
Department of Information Technology
Institut Sains Teknologi dan Kesehatan 'Aisyiyah Kendari
Kendari, Southeast Sulawesi, Indonesia
syaifulbachri@mail.ugm.ac.id
+62 851-5629-7969
December 17, 2025

Dr. Suzanne Bakken
Editor-in-Chief
Journal of the American Medical Informatics Association
American Medical Informatics Association

Dear Dr. Bakken,

Re: Submission of Original Research Article â€“ "High Consistency, Limited Accuracy: Evaluating Large Language Models for Binary Medical Diagnosis"

I am writing to submit our original research manuscript titled "High Consistency, Limited Accuracy: Evaluating Large Language Models for Binary Medical Diagnosis" for consideration for publication in the Journal of the American Medical Informatics Association.

PREPRINT AVAILABILITY

A preprint version of this manuscript is available on medRxiv (DOI: 10.64898/2025.12.08.25341823, posted December 2025). This preprint has demonstrated early community interest and has been shared to facilitate rapid dissemination of our findings on LLM reliability in clinical contexts.

SUMMARY OF THE WORK

This study addresses a critical gap in understanding Large Language Model (LLM) reliability for clinical applications. While LLMs have shown promise on medical examinations, their consistency and accuracy in real diagnostic tasks remain poorly characterized. We conducted a rigorous evaluation of three state-of-the-art LLMs (GPT-4o, Gemini-2.0-Flash, and Qwen-Plus) on binary heart disease diagnosis using 100 diverse clinical cases with 4 repeated assessments per case (1,200 total predictions).

NOVEL FINDINGS

Our study reveals a striking dissociation between consistency and accuracy:
â€¢ All models achieved exceptional reproducibility (99-100% consistency)
â€¢ Diagnostic accuracy remained at chance level (~50%)
â€¢ The consistency-accuracy gap reached ~50 percentage points
â€¢ Models showed systematic bias toward positive diagnosis (49-51 false positives vs 0-1 false negatives)
â€¢ Prompt engineering had minimal impact (<3% prediction change)
â€¢ Error patterns were highly systematic across all three models

SIGNIFICANCE AND IMPACT

This work makes several important contributions:

1. METHODOLOGICAL INNOVATION: First systematic evaluation of consistency versus accuracy in LLM medical diagnosis, introducing a rigorous multiple-run protocol

2. THEORETICAL CONTRIBUTION: Demonstrates that high consistency does not guarantee accuracy in LLM applications, challenging conventional assumptions about AI reliability

3. CLINICAL RELEVANCE: Provides evidence-based recommendations for appropriate LLM deployment, suggesting supplementary rather than primary diagnostic roles

4. PRACTICAL IMPACT: Informs responsible AI development and deployment in healthcare settings

WHY JAMIA?

This manuscript is an excellent fit for JAMIA because:
â€¢ Aligns with the journal's focus on AI in medicine and clinical decision support
â€¢ Addresses timely concerns about LLM reliability in healthcare
â€¢ Provides rigorous empirical evidence with immediate clinical implications
â€¢ Appeals to diverse readership (clinicians, AI researchers, policymakers)
â€¢ Contributes to ongoing dialogue about responsible AI in medicine

DECLARATIONS

â€¢ This manuscript represents original work not previously published or under consideration elsewhere
â€¢ A preprint version is available on medRxiv for community feedback and rapid dissemination
â€¢ All authors have approved the manuscript and agree with submission to JAMIA
â€¢ We have no conflicts of interest to declare
â€¢ The study used publicly available de-identified data and did not require IRB approval
â€¢ All data, code, and analysis scripts will be made publicly available upon acceptance

COMPETING INTERESTS

We have no competing interests to declare. We acknowledge API access from OpenAI, Google, and Alibaba but received no funding or compensation from these organizations.

MANUSCRIPT DETAILS

â€¢ Main manuscript: ~4,900 words (within JAMIA 5,000-word limit)
â€¢ Figures: 3 main figures (7-panel comprehensive analysis, confusion matrices, prompt comparison)
â€¢ Tables: 5 main tables
â€¢ Supplementary materials: Detailed data, code repository, additional analyses
â€¢ References: 8 citations (focused on high-impact recent publications)

We believe this work represents an important contribution to understanding LLM capabilities and limitations in clinical medicine. The findings have immediate implications for AI deployment in healthcare and will be of broad interest to your readership.

Thank you for considering our manuscript for publication in JAMIA. We look forward to your response and are happy to provide any additional information as needed.

Yours sincerely,

Syaiful Bachri Mustamin
Department of Information Technology
Corresponding Author
syaifulbachri@mail.ugm.ac.id
+62 851-5629-7969

Co-authors:
Dwi Anggriani â€“ Institut Sains Teknologi dan Kesehatan 'Aisyiyah Kendari
Muhammad Atnang â€“ Institut Sains Teknologi dan Kesehatan 'Aisyiyah Kendari
Kartini Aprilia Pratiwi Nuzry â€“ Institut Sains Teknologi dan Kesehatan 'Aisyiyah Kendari



MANUSCRIPT HIGHLIGHTS (for online submission form):

â€¢ First systematic evaluation of LLM consistency versus accuracy in medical diagnosis
â€¢ 1,200 predictions from three state-of-the-art models with rigorous checkpoint system
â€¢ 99-100% consistency but only 50% accuracy â€“ unprecedented 50-point gap
â€¢ Systematic positive diagnosis bias (49-51 false positives, 0-1 false negatives)
â€¢ Prompt engineering had minimal effect, suggesting deep-rooted model behavior
â€¢ Recommends LLMs as supplementary tools, not primary diagnostic systems
